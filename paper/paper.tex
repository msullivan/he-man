\documentclass[preprint]{sigplanconf}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=black,citecolor=black]%
{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}

\usepackage{listings}
\lstset{
  language=Haskell,
  basicstyle=\small\ttfamily,
  frame=trbl,
  basewidth={0.5em,0.45em},
%  commentstyle=\ttfamily\color{ForestGreen},
  literate=*{+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
            {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
            {\\\\}{{\char`\\\char`\\}}1
            {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
            {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2
            %{\ .}{{$\circ$}}2 {\ .\ }{{$\circ$}}2
            {>>}{{>>}}2 {>>=}{{>>=}}2
            {|}{{$\mid$}}1
}

\lstnewenvironment{egcode}
  {\lstset{frame=TRBL}}
  {\lstset{frame=trbl}}

\lstnewenvironment{code}
  {\lstset{frame=}}
  {}

\newenvironment{smallverbatim}{\endgraf\small\verbatim}{\endverbatim} 
\renewcommand{\t}{\texttt}
\renewcommand{\b}{\textbf}
\renewcommand{\i}{\textit}

\newcommand{\prettybox}[1]{\fbox{\parbox{\linewidth}{#1}}}

% A bunch of crazy BNF TeX I wrote once
\def\bnf#1{\prettybox{\halign{##\hfil& \hfil ##\hfil& \ ##\hfil\cr #1}}}
\def\p#1{& = & #1 \cr}
\def\pp#1{& & #1 \cr}
\def\a#1{& $\mid$ & #1 \cr}

% XXX: We need to cite ElliottEtAl somewhere!
% XXX: standardize on IO vs I/O
% XXX: standardize on domain-specific vs domain specific

%XXX: new title?
\title{He-Man: A domain specific language for lightweight concurrency}
%\subtitle{I said hey, what's goin' on}
\authorinfo{Carlo Angiuli}{Carnegie Mellon University}{cangiuli@cs.cmu.edu}
\authorinfo{Michael Sullivan}{Carnegie Mellon University}{mjsulliv@cs.cmu.edu}

\begin{document}
\maketitle

% TODO: talk about type system, runtime improvements, optimizations

\begin{abstract}
The event-driven model is the gold standard for highly concurrent network
application programming; while threaded code is easier to write and reason
about, it is considerably less scalable. We observe that these paradigms are not
only interchangeable, but primarily confined to an application's core control
flow; we propose a hybrid model in which programmers express this core logic at
a high level of abstraction, yet are free to implement the remainder of the
application at a low level.

This paper describes the design and Haskell implementation of He-Man, a domain
specific language for network application programming which presents a
sequential thread-like abstraction, but compiles to performant event-driven C
code. Our implementation is available at
\url{https://github.com/msullivan/he-man}. %\cite{HeMan}
\end{abstract}

\section{Introduction}

Modern network servers, like HTTP, IRC, and multiplayer games, need to support
many simultaneous, possibly idle, connections---this is known as the C10K
(``10,000 client'') problem \cite{Kegel}. Because I/O latency is high,
particularly over a network, our goal is to process ready clients while others
are blocked on I/O. To achieve maximum throughput, such servers are usually
written in low-level languages like C.

The simplest way to achieve this concurrency is to use kernel threads, like the
industry-standard Apache web server \cite{Apache}. These incur a fair amount of
overhead, and do not allow control over scheduling; they waste time, for
example, yielding to I/O blocked clients.

More performant web servers, such as Nginx \cite{Nginx} and Lighttpd
\cite{Lighttpd}, use non-blocking I/O routines, multiplexed at a single call
site (the ``event loop''). This allows one thread to serve many clients,
handling each only when its I/O has completed. This event-driven model requires
the routines to explicitly yield to the event loop, forcing programmers to
restructure their code as a state machine, save state across function
boundaries, and implement a scheduler. 

Although the event-driven model is typically chosen by developers who wish to
maximize performance (as with Nginx and Lighttpd), von Behren, Condit, and
Brewer \cite{vonBehrenConditBrewer} argue that events are an unnatural
abstraction for this problem domain, and that an appropriate threading library
(in particular, without preemption) can achieve equivalent performance.

In an oft-cited 1979 paper, Lauer and Needham \cite{LauerNeedham} argue that the
threaded and event-driven models are dual, where the thread scheduler plays the
role of an event loop. Then the translation from threads is simply trampolining
continuation-passing-style, where, in this case, I/O operations must yield.

The idea of implementing custom schedulers for lightweight thread abstractions
is not new, and has been used to great effect in functional language runtimes
like GHC \cite{MarlowEtAl}. Li and Zdancewic \cite{LiZdancewic} have developed
monadic abstractions in Haskell for threaded and event-driven concurrency, for
the same problem domain of scalable network applications; their implementation
draws upon the concurrency and synchronization support in the GHC runtime.

We observe that, although concurrency is critical to network applications
because I/O dominates computation time, core I/O routines comprise a small
portion of an application's program logic, which is otherwise devoted to
protocol implementation, caching, etc. We might expect that our concurrency
abstractions can be similarly confined; however, the above solutions require
writing the entire application in Haskell, or at least writing the core in
Haskell and making liberal use of the FFI.

Our contribution is to distill the Lauer-Needham duality to its essence, by
compiling from a simple thread abstraction to self-contained event-driven C
code. This abstraction, He-Man: Haskell Event Manager, Apropos Networking, is a
compiled domain specific language embedded in Haskell, which offers a small
monadic language supporting thread spawning, blocking events, and external
function calls.

The He-Man system consists of a compiler written in Haskell, and a lightweight
runtime in C which links with the compiled code. He-Man allows programmers to
develop scalable network applications by expressing their I/O logic in He-Man,
and linking the resulting event loop to the rest of their application, which can
be written in C or any language which interfaces with C. We target C because it
is commonly used in this domain, and well-suited to performance-critical
applications.

In the remainder of the paper, we discuss the event-driven programming model,
our implementation of the He-Man system, and verify that its performance is
competitive with handwritten event loops.

\section{The event-driven model}

Network applications require a very constrained form of
concurrency. In most network applications, I/O (both network
and disk) latency dominates computation time, so each client's thread
of execution spends most of its time waiting on I/O. In particular, we
would like to always yield to a client no longer blocked on I/O; we
need not yield to blocked clients, nor do we (usually) need arbitrary
interleaving of execution.

In the event loop model, network I/O is done using non-blocking
\t{read} and \t{write} calls and all of the blocking for I/O is
centralized in a single call to a multiplexing system call such as
\t{select} or \t{epoll}. The multiplexing call will block until some 
I/O is ready to be performed, and indicates to the application
which file descriptors are ready. To decide how to handle these 
events, an application must, for each connection, have some sort of 
state machine to track what state the connection is in and what 
needs to happen next, as well as other local state.

One common scheme for doing this involves registering a function
pointer with the event loop to be called on an event. Typically each
connection is also associated with a structure of connection local
data. Instead of making a blocking system call, then, an application
registers an event with the event loop along with the function to call
when it occurs, and then returns back to the loop.

The advantage of this scheme is that it is highly scalable and can be
efficient: handling a new connection typically just involves
allocating a new structure and registering it with the event loop. The
disadvantage is that now network facing code needs to be scattered
through many small functions, with all access to connection state
mediated through a shared structure.

The event loop model is then, essentially, built around closure-
converted trampolining continuation passing style. These are well
studied problems and can easily be done mechanically in the He-Man
backend.

\section{Implementation}

The latest version of He-Man can be found at
\url{https://github.com/msullivan/he-man}.

\subsection{Front-end}

The underlying abstract syntax for the front-end He-Man language is a
fairly conventional imperative, block-structured, statement-based,
first-order language, shown in Figure \ref{fig:front-syntax}. The
notable constructs are \b{Spawn}, creating a new thread, which takes a
list of arguments and launches the associated code with those
arguments available to it, and \b{Wait}, which takes an event
expression as an argument and blocks until the event is
``ready''. Note that \b{Call} is for calling foreign functions; He-Man
does not have its own notion of function.

Since writing programs using the abstract syntax would be highly
inconvenient, we provide a monadic library for writing He-Man
programs, which allows us to leverage Haskell's do notation to write
He-Man programs using convenient imperative syntax. In this way, we
are taking advantage of monads as ``programmable semicolons''.

We define the \t{Prog} monad, which contains a \t{State} monad used to
maintain a counter for generating unique variable names and a
\t{Writer} monad that is used to build up a list of statements. We
then provide \t{Prog} wrappers for statements that add the statement
to the list of statements being built up by the \t{Writer}. The
wrappers for \b{Spawn}, \b{Assign}, \b{Wait}, and \b{Exit} simply take
the obvious arguments, construct a \t{Stmt} and add it to the writer
list. The \b{Assign} wrapper is an infix operator, and is named
``.=''. The wrappers for \b{While} and \b{If} take values in \t{Prog}
instead of statement lists, and run the \t{Writer} to extract the
lists of statements. The monadic wrapper for \b{Decl} declares a
variable (with a name made unique by appending a unique number) and
then returns the \t{Expr} that references the declared variables. This
makes declaring and using variables very natural. We also provide a
wrapper for \b{Call} that declares a fresh variable, assigns the
result of a call to it, and then returns the variable. Then,
``declaring'' a foreign function consists of writing a convenient
wrapper function that invokes the \b{Call} wrapper.

At the expression level, \t{Expr} is an instance of the \t{Num} typeclass 
so that numeric literals and operations can be used in He-Man
syntax. We also provide infix operators for other useful operations on
expressions, some of them with mildly awkward names to avoid name conflicts.

As a result, He-Man code can be written in a fairly natural style with little
need for normal Haskell code, as shown in Figure \ref{fig:code-ex}.

Although the He-Man target language does not support defining
functions, code modularity and reuse is easily supported while writing
He-Man code by defining Haskell functions that produce values in
\t{Prog}. When invoked, the code of these meta-level ``functions'' is
included directly at the call-site. This is a very powerful tool, but
can potentially result in code size explosion if used carelessly.

As an example of the power that Haskell and the monadic style gives
us, Figure \ref{fig:generic} shows our library routines for simulating
blocking network operations. \t{do\_nb\_action} takes an
\t{Expr} and a \t{Prog IntE} action representing a network call that
can return \t{EAGAIN} and produces an action that generates code to
simulate a blocking network operation. This allows us to describe how
to simulate blocking I/O in a generic way, and then invoke it to
create our concrete wrappers. (\t{.=.} is a wrapper for \b{Assign} 
that takes a \t{Prog Expr} as its second argument and the \t{sock\_*} 
functions invoke \b{Call} wrappers on the appropriate network calls.)

\begin{figure}[ht]
\centering
\bnf{
\i{Stmt}
\p{\b{Decl} (\i{Var}, \i{Type}) \i{Expr}}
\a{\b{While} \i{Expr} [\i{Stmt}]}
\a{\b{If} \i{Expr} [\i{Stmt}] [\i{Stmt}]}
\a{\b{Spawn} ([(\i{Var}, \i{Type})], [\i{Stmt}]) [\i{Expr}]}
\a{\b{Assign} \i{Expr} \i{Expr}}
\a{\b{Exp} \i{Expr}}
\a{\b{Wait} \i{Expr}}
\a{\b{Exit}}
\i{Expr}
\p{\b{Call} \i{String} [\i{Expr}]}
\a{\b{Arith} \i{ArithOp} \i{Expr} \i{Expr}}
\a{\b{ArithUnop} \i{ArithUnop} \i{Expr}}
\a{\b{RelnOp} \i{RelnOp} \i{Expr} \i{Expr}}
\a{\b{Constant} \i{String}}
\a{\b{NumLit} \i{Integer}}
\a{\b{StringLit} \i{String}}
\a{\b{Var} \i{Var}}
\i{Type} 
\p{\b{Int} $\mid$ \b{Bool} $\mid$ \b{FD}
   $\mid$ \b{Buffer} $\mid$ \b{Event} $\mid$ $\cdots$}
}
\caption{Front-end abstract syntax.}
\label{fig:front-syntax}
\end{figure}

\begin{figure}[ht]
\centering
\begin{code}
child_code = declare_thread (Int) $
  \child_fd -> do
  ev <- setup_connection child_fd
  buf <- new_buf bufsize
  while 1 $ do
    amt_read <- do_read ev buf bufsize
    ifthen (amt_read .== 0) exit
    amt_written <- full_write ev buf amt_read
    ifthen (amt_written .< amt_read) exit
\end{code}
\caption{He-Man example from echo server.}
\label{fig:code-ex}
\end{figure}

\begin{figure}[ht]
\centering
\begin{code}
do_nb_action :: IntE -> EventE -> Prog IntE
                -> Prog IntE
do_nb_action mode e action = do
  res <- var "result" Int (-1)
  while (res .< 0) $ do
    set_nb_event_mode e mode
    wait e
    res .=. action
  return res

accept (fd, e) =
  mk_fd <$> do_nb_action kEVENT_RD e (sock_accept fd)
do_read (fd, e) buf size =
  do_nb_action kEVENT_RD e (sock_read fd buf size)
do_write (fd, e) buf size =
  do_nb_action kEVENT_WR e (sock_write fd buf size)
\end{code}
\caption{Implementation of ``blocking'' network calls.}
\label{fig:generic}
\end{figure}

\subsection{Type system}

It is important to provide some sort of type discipline for He-Man
programs. Providing a type system in the front end allows us to
guarantee that the C we output does not contain type errors, vastly
simplifying development. We also take advantage of this to provide
type abstractions above and beyond C's limited type system. % XXX: bad wording
For example, He-Man's type system contains an abstract
$\b{FD}$ type that is distinct from the type of integers.

We offload the work of type checking He-Man programs to the Haskell type
checker. Our method for doing this is fairly standard, following Leijen and
Meijer \cite{LeijenMeijer} in using phantom types to enforce typing.

A fragment of the code implementing the He-Man type system is shown in
Figure \ref{fig:types}. The internal type and expression
representations are the datatypes \t{IExpr} and \t{IType}, and
typed expressions are represented with the \t{Expr} data type
constructor, which is a trivial wrapper around \t{IExpr} parameterized
over a phantom type. Operations on typed expressions have type
signatures that restrict them to the proper types, and then peel away
the wrapper to work on the \t{IExpr} underneath.

% XXX: say something about GADTs??
Types are represented by the \t{Type} GADT that is also parameterized
over a phantom type representing the underlying type. Expression
builder functions will convert \t{Type} values are to \t{Itype} using
the \t{toItype} function, which does a simple pass-through conversion.
The decision to make \t{Type} a GADT instead of a simple wrapper with
constructor functions in the same manner as \t{Expr} is for purely
aesthetic reasons: we felt that type annotations in He-Man code were
more clearly readable if they were capitalized, which required that
they be datatype constructors.
\footnote{The authors believe that this may be the worst reason to
  choose to use GADTs to date.}

\begin{figure}[ht]
\centering
\begin{code}
-- Some dummy types for the phantom types
data FD
data Buffer
data Event

-- The Expr types
newtype Expr a = E IExpr
type IntE = Expr Int
type FdE = Expr FD

data Type a where
  Int :: Type Int
  FD :: Type FD
  -- ...

toIType :: Type a -> IType
toIType Int = IInt
toIType FD = IFD
-- ...

-- Lift functions over IExprs to ones over Exprs
typ1 :: (IExpr -> IExpr) -> (Expr a -> Expr b)
typ1 f (E e1) = E (f e1)
typ2 :: (IExpr -> IExpr -> IExpr) ->
        (Expr a -> Expr b -> Expr c)
typ2 f (E e1) (E e2) = E (f e1 e2)

-- Some typed He-Man functions
(.<) :: IntE -> IntE -> BoolE
(.<) = typ2 (RelnOp Lt)
(.==) :: Expr a -> Expr a -> BoolE
(.==) = typ2 (RelnOp Eq)
var :: String -> Type a -> Expr a -> Prog (Expr a)
var = ...
\end{code}
\caption{He-Man expression typing} % XXX
\label{fig:types}
\end{figure}

Type checking foreign function calls and thread declaration and
spawning is somewhat more interesting.  For foreign function calls,
our main concern was being able to write a single wrapper for call
that handles a varying number of typed arguments. We want more than
this, however: we want to ensure that both the code for a declared
thread uses its arguments properly at the declared types code and that
spawning threads provides arguments of the correct types.
% and maybe a bit novel? I dunno.

A fragment of the code implementing typing for these features is shown
in Figure \ref{fig:arg-packets}. The key is the multi-parameter type
class \t{ArgPacket}. \t{ArgPacket} is parameterized over related
tuples \footnote{Technically speaking, the unary \t{ArgPacket}s are
  not actually tuples.} of expressions and types. The idea is that
there exists an instance \t{ArgPacket exps tys} if and only if
\t{exps} and \t{tys} are tuples of \t{Expr}s and \t{Type}s,
respectively, the tuples have the same number of elements, and for
each pair of corresponding elements in the two tuples, the \t{Type}
represents the type of the \t{Expr} (that is, they have the same
phantom type argument). To enforce this one-to-one correspondence and
to allow the Haskell inferencer to use the information it provides, we
use functional dependencies % XXX: cite, or something?
to declare that both \t{exps} and \t{tys} are uniquely determined by
the other.

Then, by parameterizing the wrapper functions for foreign function
calls and thread declaration and spawning over \t{ArgPacket exps tys},
we get the desired typing guarantees.
% XXX: is this explained fully?

\begin{figure}[ht]
\centering
\begin{code}
class ArgPacket exps tys | exps -> tys,
                           tys -> exps where
  toIExprList :: exps -> [IExpr]
  makeVars :: [String] -> exps
  toITypeList :: tys -> [IType]

instance ArgPacket (Expr a) (Type a) where
  toIExprList (E e) = [e]
  makeVars [x] = E (Var x)
  toITypeList t = [toIType t]
instance ArgPacket (Expr a, Expr b) (Type a, Type b) where
  toIExprList (E e1, E e2) = [e1, e2]
  makeVars [x1, x2] = (E (Var x1), E (Var x2))
  toITypeList (t1, t2) = [toIType t1, toIType t2]
-- ...

declare_thread :: (ArgPacket exps tys) =>
                  tys -> (exps -> Prog ()) ->
                  ThreadCode exps
declare_thread = ...
spawn :: ArgPacket exps tys =>
         ThreadCode exps -> exps ->
         Prog ()
spawn = ...
call :: ArgPacket exps tys =>
        Prim -> Type c -> exps ->
        Prog (Expr c)
call = ...

\end{code}
\caption{He-Man argument packets} % XXX
\label{fig:arg-packets}
\end{figure}

\subsection{Back-end}

\begin{figure}[ht]
\centering
\bnf{
\i{Thread}
\p{(\i{thread\_label}, [(\i{Var}, \i{Type})])}
\i{Block}
\p{(\i{label}, \i{thread\_label}, [\i{Stmt}], \i{Tail})}
\i{Tail}
\p{\b{Goto} \i{label}}
\a{\b{GotoWait} \i{Expr} \i{label}}
\a{\b{If} \i{Expr} ([\i{Stmt}], \i{Tail}) ([\i{Stmt}], \i{Tail})}
\a{\b{Exit}}
\i{Stmt}
\p{\b{Decl} (\i{Var}, \i{Type}) \i{Expr}}
\a{\b{Assign} \i{Expr} \i{Expr}}
\a{\b{Exp} \i{Expr}}
\a{\b{Spawn} \i{label} [((\i{Var}, \i{Type}), \i{Expr})]}
}
\caption{Back-end abstract syntax.}
\label{fig:back-syntax}
\end{figure}

The next several passes convert our front-end grammar to a back-end grammar,
shown in Figure \ref{fig:back-syntax}, which closely resembles the C code we
ultimately generate. In particular, a back-end program is a list of code
\i{Block}s, each belonging to one of a list of \i{Thread}s. \i{Expr}s remain
unchanged from the front-end, but critically, control flow is relegated to
\i{Tail} position in each block.

Our back-end's main task is to convert our linear front-end code into a state
machine of code blocks. This occurs in our \t{flattenPrgm} pass, which passes
through program \i{Stmt}s in reverse order, generating uniquely-named blocks
whose only control-flow consists of (non-nested) tail-position jumps to other
blocks. Threads are identified with their first block.
% TODO discuss the transformations

%As an illustrative example, consider encountering an \b{If} statement in our
%backwards pass, where we have access to the translation of the later
%statements, as well as the earlier statements. Morally, we would like to
%translate this to a conditional jump to the translation of either the first or
%second arm, each of which is terminated by a jump to the later statements.
%(Note that \t{flattenPrgm} leaves all optimization to the next pass.)

%We package up the later statements in a new block, and then translate the
%preceding statements, terminated by a tail-position conditional \b{If}. We also
%translate each arm of the original \b{If}, terminated by a tail-position
%\b{Goto} to the block containing the later statements. Importantly, all three
%of these recursive translations may generate new blocks, which will be
%collected automatically by the \t{Writer} monad.

%Because blocking I/O may only happen in the main loop, we also terminate a
%block after any blocking I/O call, by inserting a \b{GotoWait} to the block
%containing the later statements. \b{GotoWait} is identical to \b{Goto} except
%to signal to later passes that the thread \emph{must} yield to the main loop at
%this location, and thus the goto must not be optimized away.
% TODO for concurrency-related reasons

This pass generates a correct, albeit unnecessarily large, state machine with
many empty blocks. Over the next few passes, our goal is to shrink this state
machine as much as possible, because yielding to the main loop is the only
overhead in the He-Man system. Although these passes are, strictly speaking,
optimizations, they are very important for performance.

Our \t{simplifyJumps} pass traverses the program collecting empty blocks,
redirecting control flow to its ultimate destination. In particular, we often
introduce nested \b{If}s in tail-position, for example, before an \t{if}
statement at the end of a \t{while} loop, where control resumes in one of three
blocks.

At this point, we need to eliminate spurious control flow edges from our state
machine in order to enable further block elimination. To do this, we perform
block-local constant propagation and folding, and dead code elimination. At face
value, it is not important for us to optimize straight-line code: our output is
further optimized by a C compiler, and execution time is dominated by I/O, not
computation. However, simple constant folding eliminates many \t{if} statements
%TODO examples, justification

Once our 
% TODO fuseBlocks pass

At this point, many blocks refer to variables declared in other blocks. The
\t{collectFrees} pass traverses each block, collecting the variables each thread
must close over. Because our front-end ensures each variable declaration is
unique, we need not consider control flow; the set of thread-local variables is
merely the union of the used-not-declared variables in each of its blocks.  We
save this list of local variables in the appropriate \i{Thread} container. (Of
course, it would be adequate to mark all variables thread-local, but this would
negatively impact our per-thread memory overhead.)

From this point, the path to C code is fairly straightforward. Concretely, we
transform our back-end grammar to the AST provided by the Language.C package,
which we then output (as C source) to a file. For each thread, we generate a
\t{struct} \t{thread$n$\_t} declaration containing a \t{thread\_t} struct with
generic thread control information, followed by all thread-local variables. Each
block is translated to a function taking as argument a \t{thread\_t} passed in
from the main loop. It casts this to the \t{struct} type for its thread in order
to access thread-local variables.

\i{Stmt}s are translated straightforwardly; threads are spawned by allocating a
new \t{struct} for the corresponding thread, setting its continuation to the
first block in the thread, and adding it to the list of runnable threads.
\i{Expr}s and \i{Tail}s are similarly straightforward; variables in the thread
\t{struct} must be replaced by references to their thread-local value, while
other variables are guaranteed to be block-local. Finally, we must also generate
a \t{main} function which spawns the first thread and jumps to the main loop.
  
\subsection{Runtime}

The He-Man runtime is written in C and provides a state machine based
thread scheduling model. In the view of the runtime, a thread consists
of some bookkeeping state, some private state, and the next
continuation function the thread is to run. The main part of the
runtime's state consists of the runqueue, which contains a list of all
currently runnable threads.

Continuation functions take a pointer to the thread information,
perform some computation (such as making non-blocking I/O calls),
update the continuation field in the thread data, and return whether
the thread is still runnable; to block, a continuation function
registers itself as blocking on an event and returns false; to exit,
it frees the thread structure and returns false.  Running a thread,
then, consists of repeatedly invoking the thread's continuation
function until it returns false. To prevent a thread that does not
need to block from starving the rest of the system, after some number
of invocations of the continuation (currently 50), the thread is
paused and put on the back of the runqueue.

The He-Man runtime main loop is very simple, then: each worker thread
loops indefinitely, and on each iteration it removes the thread at the
head of the runqueue (if it exists) and runs it, and polls for I/O
events. A global runqueue is shared between threads; a more clever
runtime could have per-worker-thread runqueues and do some sort of
work stealing.

The runtime provides a blocking mechanism based on an event
abstraction. To the runtime, an event consists of a type tag, a
pointer to a thread that is blocked on it and some event type specific
data (such as a file descriptor or a pointer to an associated
channel). Events are level-triggered: blocking on an event will return
whenever the event ``is ready'', as opposed to when the event
``becomes ready'' as in edge-triggered (using edge-triggered semantics
causes extra difficulties in an environment with multiple threads
processing events).

Currently, the He-Man runtime provides support for two types of
events: socket/pipe file I/O and asynchronous He-Man channels.  The
runtime has partial support for Linux Kernel Asynchronous IO for file
IO, using a Linux \t{eventfd} to allow \t{epoll} to wait on AIO
events. Adding new types of events that an application requires would
be simple, but require some runtime hacking.

The actual polling for I/O events is done by calling \t{epoll}
(although it would not be difficult to adapt it to use BSD's
\t{kqueue} or the more standard \t{poll} or \t{select}).  For each
event that has been returned by \t{epoll}, if a thread is waiting on
the event, the thread is added to the runqueue. If the the runqueue is
empty, the call to \t{epoll} blocks, otherwise it is called with a
timeout of zero seconds, to simply poll for events.

\section{Evaluation}\label{sec:evaluation}

To evaluate He-Man, we built several network applications with He-Man
and compared them to similar network applications built in C.  We also
discuss He-Man's memory overhead.

\subsection{Echo Server}

To compare the ease of writing event based network applications, we
built simple echo servers using both He-Man and C. The C version was
written in as an event loop driven explicit state machine using the
He-Man runtime. The C version, which is fairly tightly written and
which uses the He-Man runtime in its capacity as a somewhat generic
event based IO framework, is 98 lines of source, according to
SLOCCount. It is fairly readable, but its structure is obscured by
being split into states and the need to explicitly handle read and
write returning \t{EAGAIN} and write returning short. The state
machine has a total of five states. The He-Man version is 33 lines
long and is a very clear representation of the control flow of each
individual thread. (Additionally, the He-Man library has 17 lines of
code implementing generic routines for simulating blocking IO using
nonblocking IO and wait.) The total line counts, however, somewhat
understate the difference between the versions, since the boilerplate
for setting up connections is about the same for both versions. When
just looking at the core read/write loop, the difference is much more
apparent: the C version is 38 lines of code, and the He-Man version is
5.

The generated code is substantially less tight than the C version,
although it is unlikely to be any slower in practice. It has 10 states
and is 240 lines of C.
%This could be reduced substantially by allowing
%conditionals outside of block tail position.

\subsection{HTTP Server}

To test the suitability of our system for more complicated programs
and to demonstrate separating network logic and application logic, we
built a simple (and bad) HTTP 1.0 server. The network logic is written
in He-Man and request parsing is written in C. The C side is
implemented as a function that takes a buffer and returns whether it
forms a complete HTTP request and, if so, fills a buffer with the
file name to serve. The entire server is 54 lines of He-Man Haskell and
27 lines of C. It suffers from a number of major deficiencies, but is
complete enough to benchmark.

Our benchmark measurements are taken using ab, the Apache HTTP server
benchmarking tool \cite{ApacheAB}. Measurements were collected by
having a variable number of client threads request a file 100 times;
the experiment was repeated with a 16 kilobyte file and a 128 kilobyte
file. We ran the tests against both our He-Man HTTP server and Apache
2.2.20, installed with the default Ubuntu 11.10 settings, except for
client, thread, and process limits being adjusted upwards. Since the
He-Man runtime is currently only single-threaded, we ran the Apache
web server pinned to a single processor. Since the test repeatedly
requests the same file, it will always be in the kernel's disk cache,
and thus this test is not disk bound.

For our experiments, the server ran Linux kernel 3.0.0 on a Lenovo
Thinkpad W520 with a quad core 2.3 GHz Intel Core i7-2820QM and 8
gigabytes of RAM, and the client ran on a Lenovo Thinkpad T500 with a
Intel Core 2 Duo and 8 gigabytes of RAM.  % XXX: client specs
The machines were connected by a gigabit Ethernet link.
Unfortunately, ab is not particularly scalable, so we had trouble
testing with more than 500 clients.

Figure \ref{fig:graph128} compares our server to Apache for a 128 KB
file. Our server performs nearly identically to Apache on this load.
Figure \ref{fig:graph16} compares our server to Apache for a 16 KB
file. In this scenario, we substantially outperform Apache. We
conjecture this is because with a smaller file size, overhead for
connection setup begins to dominate, and connection setup in He-Man
consists of a few memory allocations whereas connection setup under
Apache may require spawning new OS level threads.

\begin{figure*}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{graph_128K.pdf}
\caption{Web server benchmark, 128 KB file.}
\label{fig:graph128}
\end{figure*}
\begin{figure*}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{graph_16K.pdf}
\caption{Web server benchmark, 16 KB file.}
\label{fig:graph16}
\end{figure*}
\begin{figure*}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{graph_100.pdf}
\caption{Web server benchmark, 100 B file.}
\label{fig:graph100}
\end{figure*}

\subsection{Memory Overhead}

The per-thread memory overhead imposed by He-Man is very small: it
consists of a thread id, list pointers for the scheduling queue, the
next state to enter, a pointer to the most recently received event,
and list heads and tails for lists of events owned by the thread and
buffers owned by the thread (the latter two are so that we can
automatically reclaim these resources when the thread exits). On a
64-bit system, the total overhead comes out to 64 bytes, and could
easily be reduced further (e.g., by using singly-linked lists).  For
comparison, the default thread stack size under NPTL on Linux is 2
megabytes.

% see how many threads we can spawn with Memory.hs

% Related work:
%\cite{VanderwaartCrary} re bounded time
%\cite{vonBehrenConditBrewer} re cooperative multithreading
%\cite{LiZdancewic}

% Haskell EDSLs:
%\cite{Gill}
%\cite{ElliottEtAl}
%\cite{LeijenMeijer}

\section{Related work}

\subsection{Hybrid concurrency models}

The Lauer-Needham duality \cite{LauerNeedham} between threaded and event-driven
concurrency has given rise to a number of programming models attempting to
bridge the gap between these abstractions. 

Capriccio \cite{vonBehrenEtAl} is a user-level threading library which
implements cooperative (non-preemptive) multithreading, and replaces blocking
I/O primitives in \t{libc} with a wrapper for non-blocking I/O. Capriccio allows
programmers to write C code in a threaded style, and performs a compiler
analysis to statically allocate per-thread stack space. Capriccio's goals are
similar to ours, but we feel that He-Man's approach of compiling to source is
more portable and much simpler.

Flux \cite{BurnsEtAl} is a domain-specific language intended, like He-Man, to
handle concurrency in network applications separately from the rest of the
application's logic. Flux allows programmers to declaratively specify how data
flows through the server's components, and compiles to a threaded or
event-driven runtime which implements this behavior concurrently. Flux source
code cannot express loops, except for an implicit outermost loop, as a way of
preventing deadlocks; He-Man allows more expressive control flow while making
the same guarantee.

Many functional programming languages present a native lightweight thread
abstraction. Erlang \cite{VirdingEtAl} was designed for highly concurrent
telecommunications applications, and easily scales to 20,000 clients
\cite{Hellstrom}. Concurrent ML \cite{ReppyEtAl} adds concurrency primitives to
Standard ML, implemented with front-end continuations, and a back-end
synchronization protocol. The GHC Haskell runtime supports concurrency
primitives \cite{LiEtAl} by scheduling lightweight threads onto a small number
of kernel threads \cite{MarlowEtAl}.

% XXX: remains unnecessarily general for us?

He-Man is most similar to Li and Zdancewic's Haskell implementation of
a hybrid event/thread programming model for network applications
\cite{LiZdancewic}.  Their project has similar goals to ours, but is
implemented entirely within Haskell. As a result, unlike He-Man, their
framework requires entire applications to be written in Haskell, and
incurs runtime overhead from the Haskell system.

While He-Man's goals are similar to
those of several other systems, we feel that it solves 

\subsection{Lightweight threads}

% Functional programming:
\cite{Vinoski}
\cite{Hellstrom}
FoxNet for Standard ML \cite{BiagioniEtAl}
\cite{GraunkeEtAl}
\cite{Queinnec}

The C10K problem is particularly evident in the context of HTTP
servers, which routinely maintain many concurrent connections. As we
discussed in Section \ref{sec:evaluation}, Apache does not scale
particularly well. The popular Lighttpd and Nginx HTTP server projects
were both started with the explicit goal of outperforming Apache with
respect to the C10K problem \cite{Lighttpd,Nginx}, and both use
event-based architectures similar to He-Man.

%A number of custom network stack implementations exist for functional
%languages, such as FoxNet for Standard ML \cite{BiagioniEtAl}, and

There exist C/C++ libraries for event loops\cite{libevent}, but none of these
avoid the state machine paradigm.

%% XXX: needs serious work
\section{Future work}

We also plan to expand the language with the ability to declare functions and
make non-external function calls within a thread. This will make code simpler
and shorter by allowing the programmer to abstract away common functionality
like read and write loops.

In the runtime, our current thread \t{struct}s are larger than necessary.
Because the runtime allocates a \t{struct} on every thread spawn, we should
replace our \t{malloc} calls with calls to a custom slab allocator.

We also hope to implement observable sharing, as in \cite{Gill}, to allow the
same thread to have distinct spawn sites without code duplication. This does not
add inefficiency, but does increase the size of our output code. 

\section{Conclusions}
Expressing network application logic as a compiled, embedded, domain
specific language is an elegant and practical way to build scalable
network applications without having to manually write state-machine
based event-loop code. Embedding the language in Haskell allows
powerful metaprogramming and allowed the language to be developed with
a fraction of the effort of building a full language. Compiling to C
allows C programmers to write parts of their system (for example, the
caching layer) in C while writing the network logic in
straightforward, straight-line He-Man code.

% XXX

We identify our contributions as:
* We present the idea of generating code for network facing logic from a
description written in a DSL while building the rest of the application in
C. In a way, the DSL could be considered as a method for programmatically
generating event driven frameworks customized for the application.
* We observe that converting a traditional block-structured imperative
program to a form amenable for use in an event-driven system is analogous
to CPS conversion and thus easily done automatically. (Is this actually a
contribution, or is it obvious and been said a million times before?)
* We present a case study of compiled embedded domain specific language
design and implementation
* We demonstrate that it is practical to build efficient network
applications using our system

\cite{*}

\bibliography{citations}{}
\bibliographystyle{abbrvnat}

\end{document}
