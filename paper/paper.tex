\documentclass[preprint]{sigplanconf}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=black,citecolor=black]%
{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}

\lstset{
  language=Haskell,
  basicstyle=\small\ttfamily,
  frame=trbl,
  basewidth={0.5em,0.45em},
  commentstyle=\ttfamily\color{ForestGreen},
  literate=*{+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
            {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
            {\\\\}{{\char`\\\char`\\}}1
            {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
            {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2
            %{\ .}{{$\circ$}}2 {\ .\ }{{$\circ$}}2
            {>>}{{>>}}2 {>>=}{{>>=}}2
            {|}{{$\mid$}}1
}
\lstnewenvironment{code}{\lstset{frame=}}{}

\newcommand{\prettybox}[1]{\fbox{\parbox{\linewidth}{#1}}}
\newenvironment{smallverbatim}{\endgraf\small\verbatim}{\endverbatim} 
\renewcommand{\t}{\texttt}
\renewcommand{\b}{\textbf}
\renewcommand{\i}{\textit}

% For BNF grammars:
\def\bnf#1{\prettybox{\halign{##\hfil& \hfil ##\hfil& \ ##\hfil\cr #1}}}
\def\p#1{& = & #1 \cr}
\def\pp#1{& & #1 \cr}
\def\a#1{& $\mid$ & #1 \cr}

%There exist C/C++ libraries for event loops\cite{libevent}, but none of these
%avoid the state machine paradigm.

%XXX: new title?
\title{He-Man: A domain-specific language for lightweight concurrency}
%\subtitle{I said hey, what's goin' on}
\authorinfo{Carlo Angiuli}{Carnegie Mellon University}{cangiuli@cs.cmu.edu}
\authorinfo{Michael Sullivan}{Carnegie Mellon University}{mjsulliv@cs.cmu.edu}

\begin{document}
\maketitle

\begin{abstract}
The event-driven model is the gold standard for highly concurrent network
application programming; while threaded code is easier to write and reason
about, it is considerably less scalable. We observe that these paradigms are not
only interchangeable, but primarily confined to an application's core control
flow; we propose a hybrid model in which programmers express this core logic at
a high level of abstraction, yet are free to implement the remainder of the
application at a low level.

This paper describes the design and Haskell implementation of He-Man, a
domain-specific language for network application programming which presents a
sequential thread-like abstraction, but compiles to performant event-driven C
code. Our implementation is available at
\url{https://github.com/msullivan/he-man}. %\cite{HeMan}
\end{abstract}

\section{Introduction}

Modern network servers, like HTTP, IRC, and multiplayer games, need to support
many simultaneous, possibly idle, connections---this is known as the C10K
(``10,000 client'') problem \cite{Kegel}. Because I/O latency is high,
particularly over a network, our goal is to process ready clients while others
are blocked on I/O. To achieve maximum throughput, such servers are usually
written in low-level languages like C.

The simplest way to achieve this concurrency is to use kernel threads, like the
industry-standard Apache web server \cite{Apache}. These incur a fair amount of
overhead, and do not allow control over scheduling; they waste time, for
example, yielding to I/O blocked clients.

More performant web servers, such as Nginx \cite{Nginx} and Lighttpd
\cite{Lighttpd}, use non-blocking I/O routines, multiplexed at a single call
site (the ``event loop''). This allows one thread to serve many clients,
handling each only when its I/O has completed. This event-driven model requires
the routines to explicitly yield to the event loop, forcing programmers to
restructure their code as a state machine, save state across function
boundaries, and implement a scheduler. 

Although the event-driven model is typically chosen by developers who wish to
maximize performance (as with Nginx and Lighttpd), von Behren, Condit, and
Brewer \cite{vonBehrenConditBrewer} argue that events are an unnatural
abstraction for this problem domain, and that an appropriate threading library
(in particular, without preemption) can achieve equivalent performance.

In an oft-cited 1979 paper, Lauer and Needham \cite{LauerNeedham} argue that the
threaded and event-driven models are dual, where the thread scheduler plays the
role of an event loop. Then the translation from threads is simply trampolining
continuation-passing-style, where, in this case, I/O operations must yield.

The idea of implementing custom schedulers for lightweight thread abstractions
is not new, and has been used to great effect in functional language runtimes
like GHC \cite{MarlowEtAl}. Li and Zdancewic \cite{LiZdancewic} have developed
monadic abstractions in Haskell for threaded and event-driven concurrency, for
the same problem domain of scalable network applications; their implementation
draws upon concurrency and synchronization support in the GHC runtime.

We observe that, although concurrency is critical to network applications
because I/O dominates computation time, core I/O routines comprise a small
portion of an application's program logic, which is otherwise devoted to
protocol implementation, caching, etc. We might expect that our concurrency
abstractions can be similarly confined; however, the above solutions require
writing the entire application in Haskell, or at least writing the core in
Haskell and making liberal use of the FFI.

Our contribution is to distill the Lauer-Needham duality to its essence, by
compiling from a simple thread abstraction to self-contained event-driven C
code. This abstraction, He-Man: Haskell Event Manager, Apropos Networking, is a
compiled domain-specific language embedded in Haskell, which offers a small
monadic language supporting thread spawning, blocking events, and external
function calls.

The He-Man system consists of a compiler written in Haskell, and a lightweight
runtime in C which links with the compiled code. He-Man allows programmers to
develop scalable network applications by expressing their I/O logic in He-Man,
and linking the resulting event loop to the rest of their application, which can
be written in C or any language which interfaces with C. We target C because it
is commonly used in this domain, and well-suited to performance-critical
applications.

In the remainder of the paper, we discuss the event-driven programming model,
our implementation of the He-Man system, and verify that its performance is
competitive with handwritten event loops.

\section{The event-driven model}

Network applications require a very constrained form of
concurrency. In most network applications, network and disk
I/O latency dominate computation time, so each client's thread
of execution spends most of its time waiting on I/O. In particular, we
would like to always yield to a client no longer blocked on I/O; we
need not yield to blocked clients, nor do we (usually) need arbitrary
interleaving of execution.

In the event-driven model, network I/O is performed with non-blocking
\t{read} and \t{write} calls, and all blocking on I/O is consolidated
in a single, centralized call to a multiplexing system call such as
\t{select} or \t{epoll}. This multiplexing call blocks until some 
I/O is ready to be performed, and indicates to the application
which file descriptors are ready. To decide how to handle these 
events, an application must, for each connection, maintain a
state machine to track the connection's current and next states, as 
well as any local data.

One common solution involves registering a function
pointer with the event loop to be called on an event. Typically, each
connection is also associated with a structure of connection-local
data. Instead of making a blocking system call, an application
registers an event with a function pointer to call once the event 
occurs, and then returns back to the loop.

The advantage of this scheme is that it is highly scalable and can be
efficient: handling a new connection requires only allocating a new 
structure and registering it with the event loop. The disadvantage is 
that network-facing code must be scattered across many small functions 
which call each other only through function pointers, and all connection 
state is accessed through a shared structure.

However, as we discuss in the next section, these code transformations are
familiar to functional programmers as closure conversion (to access connection
state across function boundaries), continuation-passing style (via function
pointers) with trampolining (yielding to the event loop after registering I/O).
These are well-studied conversions which can be performed mechanically by the
He-Man backend.

\section{Implementation}

The latest version of He-Man can be found at
\url{https://github.com/msullivan/he-man}.

\subsection{Front-end}

The underlying abstract syntax for the front-end He-Man language is a
fairly conventional imperative, block-structured, statement-based,
first-order language, shown in Figure \ref{fig:front-syntax}. The
notable constructs are \b{Spawn}, creating a new thread, which takes a
list of arguments and launches the associated code with those
arguments available to it, and \b{Wait}, which takes an event
expression as an argument and blocks until the event is
``ready''. Note that \b{Call} is for calling foreign functions; He-Man
does not have its own notion of function.\footnote{Adding functions or
observable sharing to He-Man could reduce output code size, but would have
little impact on performance.}

Since writing programs using the abstract syntax would be highly
inconvenient, we provide a monadic library for writing He-Man
programs, which allows us to leverage Haskell's do notation to write
He-Man programs using convenient imperative syntax. In this way, we
are taking advantage of monads as ``programmable semicolons''.

We define the \t{Prog} monad, which contains a \t{State} monad used to
maintain a counter for generating unique variable names and a
\t{Writer} monad that is used to build up a list of statements. We
then provide \t{Prog} wrappers for statements that add the statement
to the list of statements being built up by the \t{Writer}. The
wrappers for \b{Spawn}, \b{Assign}, \b{Wait}, and \b{Exit} simply take
the obvious arguments, construct a \t{Stmt} and add it to the writer
list. The \b{Assign} wrapper is an infix operator, and is named
``.=''. The wrappers for \b{While} and \b{If} take values in \t{Prog}
instead of statement lists, and run the \t{Writer} to extract the
lists of statements. The monadic wrapper for \b{Decl} declares a
variable (with a name made unique by appending a unique number) and
then returns the \t{Expr} that references the declared variables. This
makes declaring and using variables very natural. We also provide a
wrapper for \b{Call} that declares a fresh variable, assigns the
result of a call to it, and then returns the variable. Then,
``declaring'' a foreign function consists of writing a convenient
wrapper function that invokes the \b{Call} wrapper.

At the expression level, \t{Expr} is an instance of the \t{Num} typeclass 
so that numeric literals and operations can be used in He-Man
syntax. We also provide infix operators for other useful operations on
expressions, some of them with mildly awkward names to avoid name conflicts.

As a result, He-Man code can be written in a fairly natural style with little
need for normal Haskell code, as shown in Figure \ref{fig:code-ex}.

Although the He-Man target language does not support defining
functions, code modularity and reuse is easily supported while writing
He-Man code by defining Haskell functions that produce values in
\t{Prog}. When invoked, the code of these meta-level ``functions'' is
included directly at the call-site. This is a very powerful tool, but
can potentially result in code size explosion if used carelessly.

As an example of the power that Haskell and the monadic style gives
us, Figure \ref{fig:generic} shows our library routines for simulating
blocking network operations. \t{do\_nb\_action} takes an
\t{Expr} and a \t{Prog IntE} action representing a network call that
can return \t{EAGAIN} and produces an action that generates code to
simulate a blocking network operation. This allows us to describe how
to simulate blocking I/O in a generic way, and then invoke it to
create our concrete wrappers. (\t{.=.} is a wrapper for \b{Assign} 
that takes a \t{Prog Expr} as its second argument and the \t{sock\_*} 
functions invoke \b{Call} wrappers on the appropriate network calls.)

\begin{figure}[ht]
\centering
\bnf{
\i{Stmt}
\p{\b{Decl} (\i{Var}, \i{Type}) \i{Expr}}
\a{\b{While} \i{Expr} [\i{Stmt}]}
\a{\b{If} \i{Expr} [\i{Stmt}] [\i{Stmt}]}
\a{\b{Spawn} ([(\i{Var}, \i{Type})], [\i{Stmt}]) [\i{Expr}]}
\a{\b{Assign} \i{Expr} \i{Expr}}
\a{\b{Exp} \i{Expr}}
\a{\b{Wait} \i{Expr}}
\a{\b{Exit}}
\i{Expr}
\p{\b{Call} \i{String} [\i{Expr}]}
\a{\b{Arith} \i{ArithOp} \i{Expr} \i{Expr}}
\a{\b{ArithUnop} \i{ArithUnop} \i{Expr}}
\a{\b{RelnOp} \i{RelnOp} \i{Expr} \i{Expr}}
\a{\b{Constant} \i{String}}
\a{\b{NumLit} \i{Integer}}
\a{\b{StringLit} \i{String}}
\a{\b{Var} \i{Var}}
\i{Type} 
\p{\b{Int} $\mid$ \b{Bool} $\mid$ \b{FD}
   $\mid$ \b{Buffer} $\mid$ \b{Event} $\mid$ $\cdots$}
}
\caption{Front-end abstract syntax.}
\label{fig:front-syntax}
\end{figure}

\begin{figure}[ht]
\centering
\begin{code}
child_code = declare_thread (Int) $
  \child_fd -> do
  ev <- setup_connection child_fd
  buf <- new_buf bufsize
  while 1 $ do
    amt_read <- do_read ev buf bufsize
    ifthen (amt_read .== 0) exit
    amt_written <- full_write ev buf amt_read
    ifthen (amt_written .< amt_read) exit
\end{code}
\caption{He-Man example from echo server.}
\label{fig:code-ex}
\end{figure}

\begin{figure}[ht]
\centering
\begin{code}
do_nb_action :: IntE -> EventE -> Prog IntE
                -> Prog IntE
do_nb_action mode e action = do
  res <- var "result" Int (-1)
  while (res .< 0) $ do
    set_nb_event_mode e mode
    wait e
    res .=. action
  return res

accept (fd, e) =
  mk_fd <$> do_nb_action kEVENT_RD e (sock_accept fd)
do_read (fd, e) buf size =
  do_nb_action kEVENT_RD e (sock_read fd buf size)
do_write (fd, e) buf size =
  do_nb_action kEVENT_WR e (sock_write fd buf size)
\end{code}
\caption{Implementation of ``blocking'' network calls.}
\label{fig:generic}
\end{figure}

\subsection{Type system}

We provide a simple type system for He-Man programs which guarantees that we
generate C code which is free of type errors. We take advantage of this to
provide abstractions not present in C, e.g., the \b{FD} type of file descriptors
is distinct from integers in He-Man, while C draws no distinction between them.

We type-check He-Man programs with the Haskell type checker, following Leijen
and Meijer \cite{LeijenMeijer} in using phantom types. A fragment of the code
implementing the He-Man type system is shown in Figure \ref{fig:types}. Types
and expressions are internally represented by the datatypes \t{IExpr} and
\t{IType}, and typed expressions are represented with the \t{Expr} data type
constructor, which is a trivial wrapper around \t{IExpr} parameterized
over a phantom type. Operations on typed expressions have type signatures that
restrict them to the proper types, and discard the wrapper to act on the
\t{IExpr} underneath.

Types are represented by the \t{Type} GADT, which is parameterized over a
phantom type representing the underlying type. When building expressions, we
convert \t{Type} values to \t{IType} with the \t{toItype} function. The decision
to make \t{Type} a GADT instead of a simple wrapper with constructor functions
in the same manner as \t{Expr} is purely aesthetic: we felt that type
annotations in He-Man code were more clearly readable if they were capitalized,
which required them to be datatype constructors.
%\footnote{The authors believe that this may be the worst reason to
%  choose to use GADTs to date.}

\begin{figure}[ht]
\centering
\begin{code}
-- Some dummy types for the phantom types
data FD
data Buffer
data Event

-- The Expr types
newtype Expr a = E IExpr
type IntE = Expr Int
type FdE = Expr FD

data Type a where
  Int :: Type Int
  FD :: Type FD
  -- ...

toIType :: Type a -> IType
toIType Int = IInt
toIType FD = IFD
-- ...

-- Lift functions over IExprs to ones over Exprs
typ1 :: (IExpr -> IExpr) -> (Expr a -> Expr b)
typ1 f (E e1) = E (f e1)
typ2 :: (IExpr -> IExpr -> IExpr) ->
        (Expr a -> Expr b -> Expr c)
typ2 f (E e1) (E e2) = E (f e1 e2)

-- Some typed He-Man functions
(.<) :: IntE -> IntE -> BoolE
(.<) = typ2 (RelnOp Lt)
(.==) :: Expr a -> Expr a -> BoolE
(.==) = typ2 (RelnOp Eq)
var :: String -> Type a -> Expr a -> Prog (Expr a)
var = ...
\end{code}
\caption{Implementation of He-Man type system.}
\label{fig:types}
\end{figure}

Type-checking foreign function calls and thread declaration and spawning is
somewhat more interesting. We wanted a single wrapper for foreign function calls
to handle a varying number of typed arguments; we also wanted to ensure that
thread spawn sites pass in values of the correct types, and declared threads use
their arguments in type-safe ways.

A fragment of the code implementing typing for these features is shown
in Figure \ref{fig:arg-packets}. The key is the multi-parameter type
class \t{ArgPacket}. \t{ArgPacket} is parameterized over related
tuples\footnote{Technically speaking, the unary \t{ArgPacket}s are
not actually tuples.} of expressions and types. The idea is that
there exists an instance \t{ArgPacket exps tys} if and only if
\t{exps} and \t{tys} are tuples of \t{Expr}s and \t{Type}s,
respectively; the tuples have the same number of elements; and for
each pair of corresponding elements in the two tuples, the \t{Type}
represents the type of the \t{Expr} (that is, they have the same
phantom type argument).

We use functional dependencies to declare that both \t{exps} and \t{tys} are
uniquely determined by the other, which enforces this one-to-one correspondence
and allows the Haskell inferencer to use provided typing information. We obtain
our desired typing guarantees by parameterizing the wrapper functions for
foreign function calls and thread declaration/spawning over \t{ArgPacket exps tys}.

\begin{figure}[ht]
\centering
\begin{code}
class ArgPacket exps tys | exps -> tys,
                           tys -> exps where
  toIExprList :: exps -> [IExpr]
  makeVars :: [String] -> exps
  toITypeList :: tys -> [IType]

instance ArgPacket (Expr a) (Type a) where
  toIExprList (E e) = [e]
  makeVars [x] = E (Var x)
  toITypeList t = [toIType t]
instance ArgPacket (Expr a, Expr b) (Type a, Type b) where
  toIExprList (E e1, E e2) = [e1, e2]
  makeVars [x1, x2] = (E (Var x1), E (Var x2))
  toITypeList (t1, t2) = [toIType t1, toIType t2]
-- ...

declare_thread :: (ArgPacket exps tys) =>
                  tys -> (exps -> Prog ()) ->
                  ThreadCode exps
declare_thread = ...
spawn :: ArgPacket exps tys =>
         ThreadCode exps -> exps ->
         Prog ()
spawn = ...
call :: ArgPacket exps tys =>
        Prim -> Type c -> exps ->
        Prog (Expr c)
call = ...

\end{code}
\caption{Implementation of He-Man \t{ArgPacket}s.}
\label{fig:arg-packets}
\end{figure}

\subsection{Back-end}

\begin{figure}[ht]
\centering
\bnf{
\i{Thread}
\p{(\i{thread\_label}, [(\i{Var}, \i{Type})])}
\i{Block}
\p{(\i{label}, \i{thread\_label}, [\i{Stmt}], \i{Tail})}
\i{Tail}
\p{\b{Goto} \i{label}}
\a{\b{GotoWait} \i{Expr} \i{label}}
\a{\b{If} \i{Expr} ([\i{Stmt}], \i{Tail}) ([\i{Stmt}], \i{Tail})}
\a{\b{Exit}}
\i{Stmt}
\p{\b{Decl} (\i{Var}, \i{Type}) \i{Expr}}
\a{\b{Assign} \i{Expr} \i{Expr}}
\a{\b{Exp} \i{Expr}}
\a{\b{Spawn} \i{label} [((\i{Var}, \i{Type}), \i{Expr})]}
}
\caption{Back-end abstract syntax.}
\label{fig:back-syntax}
\end{figure}

The next several passes convert our front-end grammar to a back-end grammar,
shown in Figure \ref{fig:back-syntax}, which closely resembles the C code we
ultimately generate. In particular, a back-end program is a list of code
\i{Block}s, each belonging to one of a list of \i{Thread}s. \i{Expr}s remain
unchanged from the front-end, but critically, control flow is relegated to
\i{Tail} position in each block.

Our back-end's main task is to convert our linear front-end code into a state
machine of code blocks. This occurs in our \t{flattenPrgm} pass, which passes
through program \i{Stmt}s in reverse order, generating uniquely-named blocks
whose only control-flow consists of (non-nested) tail-position jumps to other
blocks. Threads are identified with their first block.

TODO here we will discuss the transformations that occur

%As an illustrative example, consider encountering an \b{If} statement in our
%backwards pass, where we have access to the translation of the later
%statements, as well as the earlier statements. Morally, we would like to
%translate this to a conditional jump to the translation of either the first or
%second arm, each of which is terminated by a jump to the later statements.
%(Note that \t{flattenPrgm} leaves all optimization to the next pass.)

%We package up the later statements in a new block, and then translate the
%preceding statements, terminated by a tail-position conditional \b{If}. We also
%translate each arm of the original \b{If}, terminated by a tail-position
%\b{Goto} to the block containing the later statements. Importantly, all three
%of these recursive translations may generate new blocks, which will be
%collected automatically by the \t{Writer} monad.

%Because blocking I/O may only happen in the main loop, we also terminate a
%block after any blocking I/O call, by inserting a \b{GotoWait} to the block
%containing the later statements. \b{GotoWait} is identical to \b{Goto} except
%to signal to later passes that the thread \emph{must} yield to the main loop at
%this location, and thus the goto must not be optimized away.
% TODO for concurrency-related reasons

This pass generates a correct, albeit unnecessarily large, state machine with
many empty blocks. Over the next few passes, our goal is to shrink this state
machine as much as possible, because yielding to the main loop is the only
overhead in the He-Man system. Although these passes are, strictly speaking,
optimizations, they are very important for performance.

Our \t{simplifyJumps} pass traverses the program collecting empty blocks,
redirecting control flow to its ultimate destination. In particular, we often
introduce nested \b{If}s in tail-position, for example, before an \t{if}
statement at the end of a \t{while} loop, where control resumes in one of three
blocks.

At this point, we need to eliminate spurious control flow edges from our state
machine in order to enable further block elimination. To do this, we perform
block-local constant propagation and folding, and dead code elimination. At face
value, it is not important for us to optimize straight-line code: our output is
further optimized by a C compiler, and execution time is dominated by I/O, not
computation. However, simple constant folding eliminates many \t{if} statements
%TODO examples, justification

TODO here we discuss the fuseBlocks pass

At this point, many blocks refer to variables declared in other blocks. The
\t{collectFrees} pass traverses each block, collecting the variables each thread
must close over. Because our front-end ensures each variable declaration is
unique, we need not consider control flow; the set of thread-local variables is
merely the union of the used-not-declared variables in each of its blocks.  We
save this list of local variables in the appropriate \i{Thread} container. (Of
course, it would be adequate to mark all variables thread-local, but this would
negatively impact our per-thread memory overhead.)

From this point, the path to C code is fairly straightforward. Concretely, we
transform our back-end grammar to the AST provided by the Language.C package,
which we then output (as C source) to a file. For each thread, we generate a
\t{struct} \t{thread$n$\_t} declaration containing a \t{thread\_t} struct with
generic thread control information, followed by all thread-local variables. Each
block is translated to a function taking as argument a \t{thread\_t} passed in
from the main loop. It casts this to the \t{struct} type for its thread in order
to access thread-local variables.

\i{Stmt}s are translated straightforwardly; threads are spawned by allocating a
new \t{struct} for the corresponding thread, setting its continuation to the
first block in the thread, and adding it to the list of runnable threads.
\i{Expr}s and \i{Tail}s are similarly straightforward; variables in the thread
\t{struct} must be replaced by references to their thread-local value, while
other variables are guaranteed to be block-local. Finally, we must also generate
a \t{main} function which spawns the first thread and jumps to the main loop.
  
\subsection{Runtime}

The He-Man runtime is a multithreaded C program which provides a generic state
machine thread scheduling model. To the runtime, a thread consists of some
bookkeeping state, some private state, and the thread's next continuation
function. The runtime's state is primarily in the runqueue, which contains a
list of all currently runnable threads.

Each continuation function takes a pointer to the thread information,
performs some computation (e.g., making non-blocking I/O calls),
updates the continuation field in the thread data, and returns whether
the thread is still runnable. To block, a continuation function
registers itself as blocking on an event and returns false; to exit,
it frees the thread structure and returns false. Running a thread,
then, consists of repeatedly invoking the thread's continuation
function until it returns false. To prevent a thread that does not
need to block from starving the rest of the system, after a continuation is
invoked some number of times (currently 50), the thread is paused and moved to
the back of the runqueue.

The He-Man runtime main loop is very simple: each worker thread
loops indefinitely, and on each iteration it removes the thread at the
head of the runqueue (if it exists) and runs it, and polls for I/O
events. A global runqueue is shared between threads; a fancier 
implementation could maintain per-worker-thread runqueues and use
work stealing.

The runtime provides a blocking mechanism based on an event
abstraction. To the runtime, an event consists of a type tag, a
pointer to a thread that is blocked on it and some event type specific
data (such as a file descriptor or a pointer to an associated
channel). Events are level-triggered: blocking on an event will return
whenever the event ``is ready'', not when the event ``becomes ready''
(edge-triggered). We make this design decision because edge-triggered semantics
cause difficulties in an environment where multiple threads are processing
events.

Currently, the He-Man runtime provides support for two types of
events: socket/pipe file I/O and asynchronous He-Man channels.  The
runtime has partial support for Linux Kernel Asynchronous I/O for file
I/O, using a Linux \t{eventfd} to allow \t{epoll} to wait on asynchronous I/O
events. Adding new types of events that an application requires would
be simple, but require some runtime hacking.

The actual polling for I/O events is done by calling \t{epoll}, and could be
easily adapted to BSD's \t{kqueue}, or the more standard \t{poll} or \t{select}.
For each event that \t{epoll} returns, if a thread is waiting on that event, the
thread is added to the runqueue. If the the runqueue is empty, the call to
\t{epoll} blocks; otherwise it is called with a timeout of zero seconds, to
simply poll for events.

\section{Evaluation}\label{sec:evaluation}

To evaluate He-Man, we built several network applications with He-Man
and compared them to similar network applications built in C.

\subsection{Echo Server}

To compare the ease of writing event-driven network applications, we wrote
simple echo servers in both He-Man and C. The C version was written as an
explicit state machine using the He-Man runtime in its capacity as a generic
event-driven I/O framework.  This code is fairly tightly written, and consists
of 98 lines of source code, according to SLOCCount.  It is fairly readable, but
its structure is obscured by being split into states, and the need to explicitly
handle read and write returning \t{EAGAIN}, or write returning short. The state
machine has a total of five states.

The He-Man version is 33 lines long and clearly represents the control flow of
each individual thread. (This does not include the He-Man library, which has 25
lines of code implementing generic routines for simulating blocking I/O using
nonblocking I/O and wait.) The total line counts, somewhat understate the
difference between the versions, since the boilerplate for setting up
connections is about the same for both versions. When just looking at the core
read/write loop, the difference is much more apparent: the C version is 38 lines
of code, and the He-Man version is 5.

The generated code is substantially longer than the C version, although not any
slower in practice; it has 10 states in 240 lines of C. This echo server easily
handles 10,000 concurrent, occasionally transmitting, connections.  With 10,000
clients, the echo server uses about 40 MB of memory, almost entirely consisting
of a 4 KB I/O buffer for each connection.

\subsection{HTTP Server}

To test the suitability of our system for more complicated programs and to
demonstrate separating network logic from application logic, we also built a
very simple HTTP server. The network logic is written in He-Man; request parsing
and response header building are implemented in C. Request parsing is handled by
function which takes a buffer and returns whether it forms a complete HTTP
request; if so, it fills a buffer with the file name to serve. The entire server
is 68 lines of He-Man and 39 lines of C. Although it is very incomplete as an
HTTP server, it is sufficient for benchmarking purposes. We add some useless
headers for padding, to ensure that it sends the same amount of data as the
complete servers we benchmark against.

Our benchmark measurements are taken using weighttp \cite{weighttp}, an http
benchmarking tool associated with lighttpd.  Measurements were collected by
requesting a file many times with a variable number of concurrent connections;
the experiment was repeated with a 100 byte file (80,000 requests), a 16 KB file
(30,000 requests), and a 128 KB file (8,000 requests). weighttp was run with 4
threads making requests. Since the test repeatedly requests the same file, it
should always be in the kernel's disk cache.

For our experiments, both the client and server ran Linux kernel 2.6.32 on quad
core 3.1 GHz Intel Core i5-2400 processors with 8 gigabytes of RAM. The machines
were connected over a 100 megabit Ethernet network. We ran the tests on our
He-Man HTTP server, Apache 2.2.14 (installed with the default Ubuntu 10.04 LTS
settings, except for client, thread, and process limits being adjusted upwards),
and Lighttpd 1.4.26 (installed with the default Ubuntu 10.04 LTS settings).

Each trial was run 10 times. The plots show the arithmetic mean of the number of
requests per second handled by each server; error bars show the standard
deviation.

% XXX work on the below paragraphs

Figure \ref{fig:graph100} compares the three servers while serving a
very small (100 byte) file. Measurements with small files test the
overhead of the web server more clearly than measurements with large
files, which wind up testing how efficiently the kernel can transfer
data. In this test, He-Man outperforms Apache and lighttpd across all
of our measurements. This can be attributed to factors both in He-Man
and in our server. He-Man imposes very low overhead and very low
connection creation cost, which makes it easy to quickly handle many
new connections. Our server is also much less featureful that Apache
and lighttpd, which means it needs to do less. It is difficult to
separate out these factors.

Figure \ref{fig:graph128} and Figure \ref{fig:graph16} compares our
server to Apache and lighttpd for 128 KB and 16 KB files. On these
loads, our server performs nearly identically to Apache while being
outperformed by the highly-turned lighttpd. In these tests, both
Apache and He-Man begin to handle fewer requests per second above some
number of concurrent requests (about 400 for the 16 KB file and 300
for the 128 KB file). We investigated the He-Man httpd server's
behavior in these tests, and found that the measured slowdown in
requests/second occured when, after rapidly processing most of the
requests in a test batch, a few requests would spend a very long time
waiting to connect, causing a pause at the end of the run. During
these pauses, both the client and the server were blocked in the
kernel, waiting for network events. This strongly suggests to us that
the problem is not with the He-Man compilation phase but that our web
server would benefit from more careful tuning of network interactions
(which may require improvements to the runtime).

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{graph_100.pdf}
\caption{Web server benchmark, 100 byte file.}
\label{fig:graph100}
\end{figure*}
\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{graph_16K.pdf}
\caption{Web server benchmark, 16 KB file.}
\label{fig:graph16}
\end{figure*}
\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{graph_128K.pdf}
\caption{Web server benchmark, 128 KB file.}
\label{fig:graph128}
\end{figure*}

\subsection{Memory Overhead}

The per-thread memory overhead imposed by He-Man is very small: it consists of a
thread id, list pointers for the scheduling queue, the next state to enter, a
pointer to the most recently received event, and list heads and tails for lists
of events owned by the thread and buffers owned by the thread.  (The event lists
allow us to automatically reclaim resources when a thread exits). On a 64-bit
system, the total overhead comes out to 64 bytes, and could be reduced further.
For comparison, the default thread stack size under NPTL on Linux is 2 MB.

\section{Related work}

\subsection{Hybrid concurrency models}

The Lauer-Needham duality \cite{LauerNeedham} between threaded and event-driven
concurrency has given rise to a number of programming models attempting to
bridge the gap between these abstractions. 

Capriccio \cite{vonBehrenEtAl} is a user-level threading library which
implements cooperative (non-preemptive) multithreading, and replaces blocking
I/O primitives in \t{libc} with a wrapper for non-blocking I/O. Capriccio allows
programmers to write C code in a threaded style, and performs a compiler
analysis to statically allocate per-thread stack space. Capriccio's goals are
similar to ours, but we feel that He-Man's approach of compiling to source is
more portable and much simpler.

Flux \cite{BurnsEtAl} is a domain-specific language intended, like He-Man, to
handle concurrency in network applications separately from the rest of the
application's logic. Flux allows programmers to declaratively specify how data
flows through the server's components, and compiles to a threaded or
event-driven runtime which implements this behavior concurrently. Flux source
code cannot express loops, except for an implicit outermost loop, as a way of
preventing deadlocks; He-Man allows more expressive control flow while making
the same guarantee.

Many functional programming languages present a native lightweight thread
abstraction. Erlang \cite{VirdingEtAl} was designed for highly concurrent
telecommunications applications, and easily scales to 20,000 clients
\cite{Hellstrom}. Concurrent ML \cite{ReppyEtAl} adds concurrency primitives to
Standard ML, implemented with front-end continuations, and a back-end
synchronization protocol. The GHC Haskell runtime supports concurrency
primitives \cite{LiEtAl} by scheduling lightweight threads onto a small number
of kernel threads \cite{MarlowEtAl}.

Li and Zdancewic \cite{LiZdancewic} have developed a hybrid concurrency monad in
Haskell for building scalable network applications. Their implementation uses
the CPS monad to represent computations as continuations in a ready queue, and
gives the illusion that I/O is blocking in each thread, while it is actually
handled with foreign calls to \t{epoll}. This concurrency monad is executed in
Haskell, unlike He-Man programs, which are compiled for speed and portability
\cite{ElliottEtAl}.

\subsection{Functional network programming}

In addition to the concurrency models mentioned above, a number of functional
languages have network libraries specifically tailored to concurrency issues,
like Erlang's TCP/IP suite \cite{ParisEtAl}, and the FoxNet library for Standard
ML \cite{BiagioniEtAl}, which uses continuations to implement coroutines for
cooperative multithreading.

It is important to note that in environments providing cooperative
multithreading, like Capriccio, FoxNet, and He-Man, while the runtime guarantees
that no thread monopolizes execution while waiting for I/O, it is certainly
possible for one thread to monopolize execution by running indefinitely.
Bounding execution time is a difficult problem which has been studied in the
context of grid computing \cite{VanderwaartCrary}. The He-Man compiler
guarantees that no code block contains an infinite loop; unbounded execution can
only occur in calls to external functions.

The Scheme community often uses continuations to develop web applications which
robustly handle client state despite the statelessness of HTTP. This can be
accomplished either by CPSing a direct-style program \cite{GraunkeEtAl} or by
modifying a HTTP server to explicitly store continuations \cite{Queinnec}.

\section{Conclusion}

The Lauer-Needham duality suggests that the performance of event-driven
concurrent code should be achievable with simpler threaded semantics. We propose
a model of network application programming which completely separates I/O logic,
which requires a tuned concurrent implementation, from largely single-threaded
protocol and implementation details. 

We present He-Man, a domain-specific language for expressing network application
I/O in a straightforward threaded abstraction, which compiles to efficient
event-driven C code. We demonstrate that it is practical to build efficient
network applications with a combination of He-Man and C code, and unlike other
hybrid concurrency systems, the He-Man runtime is very compact and easily
modified.

\bibliography{citations}{}
\bibliographystyle{abbrvnat}

\end{document}
